{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4: Neighborhood-based Collaborative Filtering for Rating Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we generate personalized recommendations for the first time. We exploit rating similarities among users and items to identify similar users and items that assist in finding the relevant items to recommend for each user.\n",
    "\n",
    "This describes the fundamental idea behind Collaborative Filtering (CF) and using kNN is a neighborhood-based approach towards CF. In a later unit we will also have a look at model-based approaches.\n",
    "\n",
    "This is also the first time we try to predict user ratings for unknown items using rating predictions to take the top-$N$ items with the highest rating predictions and recommend those to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys_training.data import Dataset\n",
    "from recsys_training.evaluation import get_relevant_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k_ratings_filepath = '../../data/raw/ml-100k/u.data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(ml100k_ratings_filepath)\n",
    "data.rating_split(seed=42)\n",
    "user_ratings = data.get_user_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind this recommender is to use item ratings of the $k$ most similar users (neighbors). We identify those _nearest neighbors_ with a similarity metric which we apply to the ratings both, root user and possible neighbor, have in common. Similarity thereby means having a similar opinion on movies.\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "1. Compute user-user similarities (we use the Pearson Correlation Coefficient here, but feel free to try other similarity metrics)\n",
    "\n",
    "2. For each user:\n",
    "\n",
    "    1. Get the k nearest neighbors along with their similarities\n",
    "    2. Collect the neighborhood item ratings and ignore those already rated by the root user\n",
    "    3. Item Rating Prediction: Compute the similarity-weighted sum of neighborhood item ratings\n",
    "    4. Recommendations: Get the $N$ items with the highest ratings that have a minimum rating count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. User-User Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_metric = 'pearson'\n",
    "user_user_sims = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_sim(a: int, b: int,\n",
    "                   entity_ratings: Dict[int, float],\n",
    "                   metric: str = 'pearson') -> tuple:\n",
    "    \"\"\"\n",
    "    Cosine Similarity\n",
    "    Pearson Correlation\n",
    "    Adjusted Cosine Similarity\n",
    "    Jaccard Similarity (intersection over union) - not a good idea as it does not incorporate ratings, e.g.\n",
    "        even the same users have rated two items, highest Jaccard similarity as evidence for high item similarity,\n",
    "        their judgement may be very differently on the two items, justifying dissimilarity\n",
    "    \"\"\"\n",
    "    # 1. isolate e.g. users that have rated both items (a and b)\n",
    "    key_intersection = set(entity_ratings[a].keys()).intersection(entity_ratings[b].keys())\n",
    "    ratings = np.array([(entity_ratings[a][key], entity_ratings[b][key]) for key in key_intersection])\n",
    "    n_joint_ratings = len(ratings)\n",
    "\n",
    "    if n_joint_ratings > 1:\n",
    "        # 2. apply a similarity computation technique\n",
    "        if metric == 'pearson':\n",
    "            # Warning and nan if for one entity the variance is 0\n",
    "            try:\n",
    "                sim = np.corrcoef(ratings, rowvar=False)[0, 1]\n",
    "            # if the standard deviation of variables becomes 0\n",
    "            except RuntimeWarning:\n",
    "                sim = None\n",
    "        elif metric == 'cosine':\n",
    "            nom = ratings[:, 0].dot(ratings[:, 1])\n",
    "            denom = np.linalg.norm(ratings[:, 0]) * np.linalg.norm(ratings[:, 1])\n",
    "            sim = nom / denom\n",
    "        elif metric == 'euclidean':\n",
    "            sim = normalized_euclidean_sim(ratings[:, 0], ratings[:, 1])\n",
    "        elif metric == 'adj_cosine':\n",
    "            sim = None\n",
    "        else:\n",
    "            raise ValueError(f\"Value {metric} for argument 'mode' not supported.\")\n",
    "    else:\n",
    "        sim = None\n",
    "\n",
    "    return sim, n_joint_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pairs = itertools.combinations(data.users, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a few seconds to finish ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/recsys_training/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/anaconda3/envs/recsys_training/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "for pair in user_pairs:\n",
    "    user_user_sims[pair] = get_entity_sim(pair[0], pair[1],\n",
    "                                          user_ratings,\n",
    "                                          sim_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9759000729485333, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_user_sims[(1,4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Implement Nearest Neighbors for a given user\n",
    "\n",
    "**Task:** It's your turn again. Complete `get_k_nearest_neighbors` to return a sorted list of the $k$ nearest neighbors - identified by their id - for a given user, each along with its similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest_neighbors(user: int, k: int, user_user_sims: dict) -> List[Tuple[int, float]]:\n",
    "    neighbors = set(data.users)\n",
    "    neighbors.remove(user)\n",
    "\n",
    "    nearest_neighbors = dict()\n",
    "    for neighbor in neighbors:\n",
    "        sim = user_user_sims[tuple(sorted((user, neighbor)))][0]\n",
    "        if pd.notnull(sim):\n",
    "            nearest_neighbors[neighbor] = sim\n",
    "\n",
    "    nearest_neighbors = sorted(nearest_neighbors.items(),\n",
    "                               key=lambda kv: kv[1],\n",
    "                               reverse=True)\n",
    "    \n",
    "    return nearest_neighbors[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_neighbors = get_k_nearest_neighbors(1, k=10, user_user_sims=user_user_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(107, 1.0),\n",
       " (443, 1.0),\n",
       " (485, 1.0),\n",
       " (687, 1.0),\n",
       " (791, 1.0),\n",
       " (820, 1.0),\n",
       " (34, 0.9999999999999999),\n",
       " (240, 0.9999999999999999),\n",
       " (281, 0.9999999999999999),\n",
       " (384, 0.9999999999999999)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Obtain the Neighborhood Ratings\n",
    "\n",
    "**Task:** Now, use the nearest neighbors and get their ratings, but leave out the items our root user has already rated. Return a mapping from unknown item to a list of dicts with neighbor similarity and item rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood_ratings(user, user_neighbors: List[Tuple[int, float]]) -> Dict[int, List[Dict[str, float]]]:\n",
    "    neighborhood_ratings = {}\n",
    "    for neighbor, sim in user_neighbors:\n",
    "        neighbor_ratings = user_ratings[neighbor].copy()\n",
    "        \n",
    "        # collect neighbor ratings and items\n",
    "        for item, rating in neighbor_ratings.items():\n",
    "            add_item = {'sim': sim, 'rating': rating}\n",
    "            if item not in neighborhood_ratings.keys():\n",
    "                neighborhood_ratings[item] = [add_item]\n",
    "            else:\n",
    "                neighborhood_ratings[item].append(add_item)\n",
    "        \n",
    "    # remove known items\n",
    "    known_items = list(user_ratings[user].keys())\n",
    "    for known_item in known_items:\n",
    "        neighborhood_ratings.pop(known_item, None)\n",
    "    \n",
    "    return neighborhood_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_ratings = get_neighborhood_ratings(1, user_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(340,\n",
       "  [{'sim': 1.0, 'rating': 5.0},\n",
       "   {'sim': 1.0, 'rating': 5.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 4.0}]),\n",
       " (325, [{'sim': 1.0, 'rating': 3.0}]),\n",
       " (288,\n",
       "  [{'sim': 1.0, 'rating': 3.0},\n",
       "   {'sim': 1.0, 'rating': 3.0},\n",
       "   {'sim': 1.0, 'rating': 4.0},\n",
       "   {'sim': 1.0, 'rating': 3.0},\n",
       "   {'sim': 1.0, 'rating': 5.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 5.0}]),\n",
       " (312,\n",
       "  [{'sim': 1.0, 'rating': 4.0}, {'sim': 0.9999999999999999, 'rating': 4.0}]),\n",
       " (313,\n",
       "  [{'sim': 1.0, 'rating': 2.0},\n",
       "   {'sim': 1.0, 'rating': 4.0},\n",
       "   {'sim': 1.0, 'rating': 5.0},\n",
       "   {'sim': 1.0, 'rating': 5.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 5.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 5.0}]),\n",
       " (300,\n",
       "  [{'sim': 1.0, 'rating': 1.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 3.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 4.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 4.0}]),\n",
       " (264,\n",
       "  [{'sim': 1.0, 'rating': 3.0},\n",
       "   {'sim': 1.0, 'rating': 3.0},\n",
       "   {'sim': 1.0, 'rating': 3.0}]),\n",
       " (333,\n",
       "  [{'sim': 1.0, 'rating': 3.0},\n",
       "   {'sim': 1.0, 'rating': 5.0},\n",
       "   {'sim': 1.0, 'rating': 5.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 3.0},\n",
       "   {'sim': 0.9999999999999999, 'rating': 4.0}]),\n",
       " (1243, [{'sim': 1.0, 'rating': 3.0}]),\n",
       " (322,\n",
       "  [{'sim': 1.0, 'rating': 1.0}, {'sim': 0.9999999999999999, 'rating': 4.0}])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(neighborhood_ratings.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Compute Rating Predictions from Neighborhood Ratings\n",
    "\n",
    "**Task:** In this step, we estimate ratings for the seed user based on the neighborhood ratings. We implement a similarity weighted average of neighbor ratings for that. Return a mapping from item to its prediction and the count of neighbor ratings received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rating_pred(neighborhood_ratings: dict) -> dict:\n",
    "    rating_preds = dict()\n",
    "    for item, ratings in neighborhood_ratings.items():\n",
    "        if len(ratings) > 0:\n",
    "            sims = np.array([rating['sim'] for rating in ratings])\n",
    "            ratings = np.array([rating['rating'] for rating in ratings])\n",
    "            pred_rating = (sims * ratings).sum() / sims.sum()\n",
    "            count = len(sims)\n",
    "            rating_preds[item] = {'pred': pred_rating,\n",
    "                                  'count': count}\n",
    "        else:\n",
    "            rating_preds[item] = {'pred': None, 'count': 0}\n",
    "\n",
    "    return rating_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_preds = compute_rating_pred(neighborhood_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(340, {'pred': 4.666666666666667, 'count': 3}),\n",
       " (325, {'pred': 3.0, 'count': 1}),\n",
       " (288, {'pred': 3.8333333333333335, 'count': 6}),\n",
       " (312, {'pred': 4.0, 'count': 2}),\n",
       " (313, {'pred': 4.333333333333333, 'count': 6}),\n",
       " (300, {'pred': 2.9999999999999996, 'count': 4}),\n",
       " (264, {'pred': 3.0, 'count': 3}),\n",
       " (333, {'pred': 4.0, 'count': 5}),\n",
       " (1243, {'pred': 3.0, 'count': 1}),\n",
       " (322, {'pred': 2.5, 'count': 2}),\n",
       " (305, {'pred': 4.0, 'count': 1}),\n",
       " (327, {'pred': 4.0, 'count': 3}),\n",
       " (302, {'pred': 4.6, 'count': 5}),\n",
       " (687, {'pred': 3.0, 'count': 1}),\n",
       " (358, {'pred': 1.0, 'count': 2}),\n",
       " (323, {'pred': 2.5, 'count': 2}),\n",
       " (286, {'pred': 3.875, 'count': 8}),\n",
       " (678, {'pred': 2.0, 'count': 1}),\n",
       " (343, {'pred': 4.0, 'count': 2}),\n",
       " (644, {'pred': 3.0, 'count': 1})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rating_preds.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Compute the Top-$N$ Recommendation Items\n",
    "\n",
    "**Task:** The last step takes the rating predictions and returns the $N$ highest predictions which have a minimum rating count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_n(rating_preds: dict, min_count: int, N: int) -> OrderedDict:\n",
    "    rating_preds = {key: val for (key, val) in rating_preds.items()\n",
    "                    if val['count'] >= min_count}\n",
    "    # assuming more ratings mean higher confidence in the prediction\n",
    "    sorted_rating_preds = sorted(rating_preds.items(),\n",
    "                                 key=lambda kv: (kv[1]['pred'], kv[1]['count']),\n",
    "                                 reverse=True)\n",
    "\n",
    "    return OrderedDict(sorted_rating_preds[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_recs = compute_top_n(rating_preds, min_count=2, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(242, {'pred': 5.0, 'count': 2}),\n",
       "             (340, {'pred': 4.666666666666667, 'count': 3}),\n",
       "             (332, {'pred': 4.666666666666667, 'count': 3}),\n",
       "             (302, {'pred': 4.6, 'count': 5}),\n",
       "             (690, {'pred': 4.5, 'count': 2}),\n",
       "             (313, {'pred': 4.333333333333333, 'count': 6}),\n",
       "             (333, {'pred': 4.0, 'count': 5}),\n",
       "             (327, {'pred': 4.0, 'count': 3}),\n",
       "             (312, {'pred': 4.0, 'count': 2}),\n",
       "             (343, {'pred': 4.0, 'count': 2})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all steps in a single method `get_recommendations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user: int,\n",
    "                        user_user_sims: dict,\n",
    "                        k: int,\n",
    "                        min_count: int,\n",
    "                        N: int):\n",
    "    user_neighbors = get_k_nearest_neighbors(user, k=k, user_user_sims=user_user_sims)\n",
    "    neighborhood_ratings = get_neighborhood_ratings(user, user_neighbors)\n",
    "    rating_preds = compute_rating_pred(neighborhood_ratings)\n",
    "    top_n_recs = compute_top_n(rating_preds, min_count=min_count, N=N)\n",
    "    return top_n_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(242, {'pred': 5.0, 'count': 2}),\n",
       "             (340, {'pred': 4.666666666666667, 'count': 3}),\n",
       "             (332, {'pred': 4.666666666666667, 'count': 3}),\n",
       "             (302, {'pred': 4.6, 'count': 5}),\n",
       "             (690, {'pred': 4.5, 'count': 2}),\n",
       "             (313, {'pred': 4.333333333333333, 'count': 6}),\n",
       "             (333, {'pred': 4.0, 'count': 5}),\n",
       "             (327, {'pred': 4.0, 'count': 3}),\n",
       "             (312, {'pred': 4.0, 'count': 2}),\n",
       "             (343, {'pred': 4.0, 'count': 2})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(1, user_user_sims, 10, 2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 60\n",
    "min_count = 10\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_items = get_relevant_items(data.test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = relevant_items.keys()\n",
    "prec_at_N = dict.fromkeys(data.users)\n",
    "\n",
    "for user in users:\n",
    "    recommendations = get_recommendations(user, user_user_sims, k, min_count, N)\n",
    "    recommendations = list(recommendations.keys())\n",
    "    hits = np.intersect1d(recommendations,\n",
    "                          relevant_items[user])\n",
    "    prec_at_N[user] = len(hits)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08106382978723406"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([val for val in prec_at_N.values() if val is not None])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
