{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 2: Popularity Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we build a recommender that sorts items by popularity as of the number of ratings they received. As a result we return the $N$ most popular items as recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Dict, List\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={'figure.figsize': (16, 9.)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k_ratings_filepath = '../data/raw/ml-100k/u.data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(ml100k_ratings_filepath)\n",
    "data.rating_split(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we define _popularity_? It turns out that there can be different things justifying the popularity of content:\n",
    "- pure count: simply count the number of ratings or interactions an item received regardless of their quality\n",
    "- positive count: only count the number of ratings or interactions that we assume reflect preference towards items, e.g. ratings above user mean ratings\n",
    "- time-dependency: despite evergreen stars items may also be popular for a limited time only - how can we account for this?\n",
    "\n",
    "However, popularity ranking entails no personalization. We obtain a single popularity ranking of items which is independent from the user and serve the same top-$k$ items to every user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity based on simple Interaction Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_popularity = data.train_ratings['item'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50      471\n",
       "181     423\n",
       "258     409\n",
       "100     405\n",
       "294     394\n",
       "       ... \n",
       "1320      1\n",
       "1669      1\n",
       "1576      1\n",
       "1541      1\n",
       "1663      1\n",
       "Name: item, Length: 1651, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_order = item_popularity.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity based on positive Interaction Counts\n",
    "\n",
    "Therefore we must first remove all ratings that fall below the user rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that there are less hits, but on average the hits have a higher rating and thus are more relevant - we are recommending less, but also less shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check spearman rank correlation between both orderings to quantify the distortion in ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mean_ratings = data.train_ratings[['user', 'rating']].groupby('user').mean().reset_index()\n",
    "user_mean_ratings.rename(columns={'rating': 'user_mean_rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>user_mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.590476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.673469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.925373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>4.292683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>3.425287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>3.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>4.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>3.518519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  user_mean_rating\n",
       "0       1          3.590476\n",
       "1       2          3.673469\n",
       "2       3          2.809524\n",
       "3       4          4.333333\n",
       "4       5          2.925373\n",
       "..    ...               ...\n",
       "938   939          4.292683\n",
       "939   940          3.425287\n",
       "940   941          3.947368\n",
       "941   942          4.234375\n",
       "942   943          3.518519\n",
       "\n",
       "[943 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mean_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_ratings = data.train_ratings.merge(user_mean_ratings, on='user', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_ratings = positive_train_ratings['rating'] >= positive_train_ratings['user_mean_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/recsys_training/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "positive_train_ratings = positive_train_ratings[keep_ratings]\n",
    "positive_train_ratings.drop(columns='user_mean_rating', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>877</td>\n",
       "      <td>381</td>\n",
       "      <td>4</td>\n",
       "      <td>882677345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>431</td>\n",
       "      <td>4</td>\n",
       "      <td>891721716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>598</td>\n",
       "      <td>286</td>\n",
       "      <td>5</td>\n",
       "      <td>886711452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>886</td>\n",
       "      <td>496</td>\n",
       "      <td>4</td>\n",
       "      <td>876031952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>521</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>884478358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79989</th>\n",
       "      <td>200</td>\n",
       "      <td>673</td>\n",
       "      <td>5</td>\n",
       "      <td>884128554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79993</th>\n",
       "      <td>44</td>\n",
       "      <td>432</td>\n",
       "      <td>5</td>\n",
       "      <td>878347569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>92</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>875653307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>875072716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>82</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>878769442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42993 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating  timestamp\n",
       "0       877   381       4  882677345\n",
       "2        94   431       4  891721716\n",
       "6       598   286       5  886711452\n",
       "7       886   496       4  876031952\n",
       "9       521   184       4  884478358\n",
       "...     ...   ...     ...        ...\n",
       "79989   200   673       5  884128554\n",
       "79993    44   432       5  878347569\n",
       "79995    92    48       4  875653307\n",
       "79997     1    96       5  875072716\n",
       "79998    82   169       4  878769442\n",
       "\n",
       "[42993 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_train_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_popularity_positive = positive_train_ratings.item.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50      395\n",
       "100     319\n",
       "181     303\n",
       "174     278\n",
       "127     273\n",
       "       ... \n",
       "1534      1\n",
       "1598      1\n",
       "1630      1\n",
       "1662      1\n",
       "1631      1\n",
       "Name: item, Length: 1451, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_popularity_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_order_positive = item_popularity.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How strong do both orderings correlate with each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_counts = [[item_popularity.loc[item], item_popularity_positive[item]]\n",
    "                for item in np.intersect1d(item_popularity_positive.index.values, item_popularity.index.values)]\n",
    "joint_counts = np.array(joint_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[365, 252],\n",
       "       [105,  40],\n",
       "       [ 72,  28],\n",
       "       ...,\n",
       "       [  4,   3],\n",
       "       [  1,   1],\n",
       "       [  1,   1]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.946241194276375, pvalue=0.0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.spearmanr(joint_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Popularity Ordering for top-$N$ Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  50,  181,  258, ..., 1576, 1541, 1663])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  50,  181,  258, ..., 1576, 1541, 1663])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_order_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(N) -> Dict[int, None]:\n",
    "    recs = dict(zip(item_order[:N], [None]*N))\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: None,\n",
       " 181: None,\n",
       " 258: None,\n",
       " 100: None,\n",
       " 294: None,\n",
       " 286: None,\n",
       " 288: None,\n",
       " 1: None,\n",
       " 121: None,\n",
       " 300: None}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation the Relevance of Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_items(test_ratings: pd.DataFrame) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    returns {user: [items]} as a list of relevant items per user\n",
    "    for all users found in the test dataset\n",
    "    \"\"\"\n",
    "    relevant_items = test_ratings[['user', 'item']]\n",
    "    relevant_items = relevant_items.groupby('user')\n",
    "    relevant_items = {user: relevant_items.get_group(user)['item'].values\n",
    "                      for user in relevant_items.groups.keys()}\n",
    "\n",
    "    return relevant_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_items = get_relevant_items(data.test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143,  88, 131,  15, 239,  99, 255, 134, 210, 264, 227, 202,  59,\n",
       "        17, 203,   9,  39,  55, 251, 213,  27, 137, 180, 207, 196, 101,\n",
       "        28, 123,  13, 268, 106, 112, 222,  93, 126, 246, 257,  98,  34,\n",
       "       130, 218, 188, 242, 270, 170, 122, 120, 224,  72, 183, 190, 146,\n",
       "       167, 214, 121,   2,   5, 182,  43, 175, 252, 184])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_items[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Precision@10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute the intersection between the top-$N$ recommended items and the items each user interacted with. Ideally, we want every recommendation to be a hit, i.e. an item the user consumed. In this case the size of intersections is $N$ given $N$ recommendations which is a precision of 100% = $\\frac{N}{N}$.\n",
    "\n",
    "We compute the so called $Precision@N$ for every user and take the mean over all. The resulting metric is called _mean average precision at N_ or short $MAP@N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Compute the MAP@N for popularity recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = relevant_items.keys()\n",
    "prec_at_N = dict.fromkeys(users)\n",
    "recommendations = item_order[:N]\n",
    "\n",
    "for user in users:\n",
    "    hits = np.intersect1d(recommendations, relevant_items[user])\n",
    "    prec_at_N[user] = len(hits)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10085106382978724"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(prec_at_N.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
